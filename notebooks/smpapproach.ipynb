{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwzqNd1Vg4wi"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wtdbnguQ4aY"
      },
      "source": [
        "Mount Google Drive to access data and other repo files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjKkw5H68gM0",
        "outputId": "c434aa32-6be8-45fb-b31f-73a2fa7f0108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfgRV3ZQ8tX"
      },
      "source": [
        "Set the seed for reproducability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JD7I8qKXQ38W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v77OIPU_4IB"
      },
      "source": [
        "Clone the repository to access the other relevant files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFpCBHn9-Xl",
        "outputId": "7f9c75f9-ef3d-4a29-fcce-d594d15c051d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Self-Learning-From-Noisy-Labels'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 220 (delta 13), reused 18 (delta 13), pack-reused 200\u001b[K\n",
            "Receiving objects: 100% (220/220), 87.96 MiB | 16.43 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "/content/Deep-Self-Learning-From-Noisy-Labels\n"
          ]
        }
      ],
      "source": [
        "# clone the repo\n",
        "!git clone https://github.com/lgiesen/Deep-Self-Learning-From-Noisy-Labels.git\n",
        "\n",
        "# go to directory\n",
        "%cd Deep-Self-Learning-From-Noisy-Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyXJNDnV_4IE"
      },
      "source": [
        "Define the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJGD8fw88gM5",
        "outputId": "917601c3-cc7d-4105-a356-5bf0e307e937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "from config import batch_size, dataset_test_path, dataset_train_path, dataset_val_path\n",
        "from LoadDataset import CustomImageDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    # \"These exact values are used for normalizing data that has been pre-trained\n",
        "    # on the ImageNet dataset. They are based on the statistics of the ImageNet\n",
        "    # dataset, which consists of a large number of natural images.\"\n",
        "    # https://moiseevigor.github.io/software/2022/12/18/one-pager-training-resnet-on-imagenet/\n",
        "\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomImageDataset(file_path=dataset_train_path, transform=transform)\n",
        "val_dataset = CustomImageDataset(file_path=dataset_val_path, transform=transform)\n",
        "test_dataset = CustomImageDataset(file_path=dataset_test_path, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "# pinned memory can significantly speed up the transfer of data between the host and the device (GPU) because the GPU can directly access it\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzDPbook_4IF"
      },
      "source": [
        "Extract the image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/3.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/0.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/4.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/1.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/2.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/7.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/5.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/6.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/9.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/8.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "The extracted tar files should result in the folders 0 to 9:\n",
            "0  1  2  3  4  5  6  7\t8  9\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "time to extract all 9 tar files: \n",
        "CPU times: user 3min 46s, sys: 6min 13s, total: 10min\n",
        "Wall time: 6min 6s\n",
        "\"\"\"\n",
        "import tarfile\n",
        "import os\n",
        "from config import shared_folder_path, dataset_img\n",
        "\n",
        "# Function to extract and process files\n",
        "def extract_and_process(tar_file_path, extract_to):\n",
        "    with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {tar_file_path} to {extract_to}\")\n",
        "\n",
        "parallel_extraction = True\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Function to extract and process files\n",
        "def extract_and_process(tar_file_path, extract_to):\n",
        "    with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {tar_file_path} to {extract_to}\")\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(dataset_img, exist_ok=True)\n",
        "\n",
        "# List of tar files to extract\n",
        "tar_files = [os.path.join(shared_folder_path, f\"{i}.tar\") for i in range(10)]\n",
        "\n",
        "# Function to handle extraction in parallel\n",
        "def extract_tar_files_parallel(tar_files, extract_to):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = [executor.submit(extract_and_process, tar_file, extract_to) for tar_file in tar_files if os.path.exists(tar_file)]\n",
        "        for future in futures:\n",
        "            try:\n",
        "                future.result()  # Wait for the result to ensure any exceptions are raised\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Extract tar files in parallel\n",
        "extract_tar_files_parallel(tar_files, dataset_img)\n",
        "print(\"The extracted tar files should result in the folders 0 to 9:\")\n",
        "!ls \"{dataset_img}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define function to extract the dataset data to calculate class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQFI_PcTSbwk"
      },
      "outputs": [],
      "source": [
        "from config import randomly_sampled_img_count, dataset_sample_path, dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "def get_data():\n",
        "    # Calculate the balanced class weights because of an imbalanced dataset\n",
        "    # Read the data again for higher efficiency\n",
        "    data = pd.read_csv(dataset.replace(\"../\",\"/content/\"), header=None, sep=' ', names=['image', 'label'])\n",
        "    # Convert the labels to a numpy array\n",
        "    images = data['image'].values\n",
        "    labels = data['label'].values\n",
        "    return images, labels\n",
        "\n",
        "# Calculate the balanced class weights because of an imbalanced dataset\n",
        "_, labels = get_data()\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sm-vbi304_-"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from config import lr, momentum, weight_decay, gamma, step_size, num_classes, writer_path_smp as writer_path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# check if the GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "# Initialize the model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "# Modify the final fully connected layer to output 14 classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "# Initialize the learning rate scheduler: Decay LR by a factor of 0.1 every 5 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "# Define the hook function with the intermediate_output as the features\n",
        "def hook(module, input, output):\n",
        "    global intermediate_output\n",
        "    intermediate_output = output.detach()\n",
        "\n",
        "def reset_intermediate_output():\n",
        "    global intermediate_output\n",
        "    intermediate_output = None\n",
        "\n",
        "# Register the hook to the layer before the FC layer (AdaptiveAvgPool2d)\n",
        "hook = model.avgpool.register_forward_hook(hook)\n",
        "\n",
        "# Parallelize training across multiple GPUs\n",
        "model = torch.nn.DataParallel(model).to(device)\n",
        "\n",
        "import time\n",
        "from config import num_epochs, alpha, checkpoint_path\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter(writer_path)\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "early_stop = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define functions to calculate the prototypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvjalw_EMVEa"
      },
      "outputs": [],
      "source": [
        "def sample_images(class_id, num_samples=randomly_sampled_img_count):\n",
        "    \"\"\"\n",
        "    This function randomly samples 1280 images for each of the 14 classes\n",
        "    from the original noisy dataset (cf. Fig. 3 of \"Deep Self-Learning From Noisy Labels\").\n",
        "    Output: DataLoader\n",
        "    \"\"\"\n",
        "    # Split the dataset into images and labels\n",
        "    images, labels = get_data()\n",
        "\n",
        "    # Get indices of images corresponding to the current class\n",
        "    class_indices = (labels == class_id).nonzero()[0]\n",
        "\n",
        "    # Randomly sample the required number of images for this class\n",
        "    sampled_indices = torch.randperm(len(class_indices))[:num_samples]\n",
        "\n",
        "    # Collect the sampled images\n",
        "    sampled_class_images = images[class_indices[sampled_indices]]\n",
        "\n",
        "    # Convert the array to a list of strings with \" -1\" appended to each\n",
        "    #sampled_class_images = [f\"{item} -1\" for item in sampled_class_images]\n",
        "    sampled_class_images = np.char.replace(list(sampled_class_images), \"images\", \"extracted_images\")\n",
        "\n",
        "    # Export the samples to CSV to create a loader just like for the datasets\n",
        "    pd.DataFrame(sampled_class_images).to_csv(dataset_sample_path, sep=' ', index=False, header=False)\n",
        "    sample_dataset = CustomImageDataset(file_path=dataset_sample_path, transform=transform, sampling=True)\n",
        "    sample_loader = DataLoader(sample_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "    return sample_loader\n",
        "\n",
        "def cos_similarity(samples_features, randomly_sampled_img_count=randomly_sampled_img_count):\n",
        "    \"\"\"\n",
        "    This function computes the cosine similarity matrix for 1280 sample features for one of the 14 classes\n",
        "    Input: Sample features are the randomly sampled 1280 images from one class. It is a tensor([1280, 3, 224, 224])\n",
        "    Output: Similarity matrix of 1280 sample features for one of the 14 classes\n",
        "    tensor([1280, 1280])\n",
        "    \"\"\"\n",
        "    # Step 1: Flatten the image features to shape [1280, 150528]\n",
        "    flattened_features = samples_features.view(randomly_sampled_img_count, -1)\n",
        "\n",
        "    # Step 2: Normalize the features\n",
        "    normalized_features = torch.nn.functional.normalize(flattened_features, p=2, dim=1)\n",
        "\n",
        "    # Step 3: Compute the cosine similarity matrix\n",
        "    similarity_matrix = torch.mm(normalized_features, normalized_features.t())\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "from config import threshold_percentile\n",
        "def calc_similarity_threshold(similarity_matrix, percentile=threshold_percentile):\n",
        "    \"\"\"\n",
        "    This function calculates a suitable similarity threshold value for the calc_rho_density function.\n",
        "    It takes the similarity value of the data point at the specified percentile rank.\n",
        "\n",
        "    Input:\n",
        "    - similarity_matrix: cosine similarity matrix of 1280 images, torch.Size([1280, 1280])\n",
        "    - percentile: the desired percentile for threshold calculation (default is 40)\n",
        "\n",
        "    Output:\n",
        "    - threshold: numeric value between 0.0 and 1.0 representing the similarity threshold\n",
        "    \"\"\"\n",
        "    # Flatten the matrix and exclude the diagonal elements\n",
        "    flattened_matrix = similarity_matrix.flatten()\n",
        "    n = similarity_matrix.size(0)\n",
        "    mask = torch.eye(n, dtype=torch.bool)\n",
        "    non_diagonal_elements = flattened_matrix[~mask.flatten()]\n",
        "\n",
        "    # Sort the non-diagonal elements\n",
        "    sorted_elements = torch.sort(non_diagonal_elements).values\n",
        "\n",
        "    # Calculate the index for the desired percentile\n",
        "    index = int((percentile / 100.0) * len(sorted_elements))\n",
        "\n",
        "    # Retrieve the similarity threshold value\n",
        "    return sorted_elements[index].item()\n",
        "\n",
        "def calc_rho_densities(similarity_matrix, threshold):\n",
        "    \"\"\"\n",
        "    This function computes the density of the images of one class to determine\n",
        "    if they are diverse prototypes in the later stages of the programming.\n",
        "    It follows the following function: sign(x) = 1 if x > 0; sign(x) = 0 if x = 0; otherwise sign(x) = -1\n",
        "    So, if the cosine similarity (S_c) of the two images exceed the threshold, then the density is incremented by one.\n",
        "    If the threshold is equal to the S_c, then the density stays the same.\n",
        "    If the threshold is larger than S_c, then the density is reduced by 1.\n",
        "    Input: cosine similarity matrix of 1280 images (torch.Size([1280, 1280]) and the threshold (numeric value between 0 and 1)\n",
        "    Output: Densities of 1280 sample features for each of the 14 classes\n",
        "    tensor([1280])\n",
        "    \"\"\"\n",
        "    # Initialize the density vector with zeros\n",
        "    densities = torch.zeros(similarity_matrix.size()[0])\n",
        "\n",
        "    # Loop through each image\n",
        "    for i in range(similarity_matrix.size(0)):\n",
        "        # Apply the sign function\n",
        "        sign_values = torch.sign(similarity_matrix[i] - threshold)\n",
        "\n",
        "        # Calculate the density for the i-th image\n",
        "        densities[i] = torch.sum(sign_values)\n",
        "    return densities\n",
        "\n",
        "\n",
        "def calc_eta_similarity_measurement(similarity_matrix, densities):\n",
        "    \"\"\"\n",
        "    This function computes the eta value, which describes the similarity\n",
        "    measurement used to identify diverse and representative prototypes.\n",
        "    Input: cosine similarity matrix of 1280 images (torch.Size([1280, 1280]) and len(densities) = 1280\n",
        "    Output: The similarity measurement eta for each image\n",
        "    tensor([1280])\n",
        "    \"\"\"\n",
        "    # Initialize the eta tensor\n",
        "    eta = torch.zeros_like(densities)\n",
        "\n",
        "    # Get the maximum density value\n",
        "    max_density = densities.max()\n",
        "\n",
        "    for i in range(len(densities)):\n",
        "        if densities[i] < max_density:\n",
        "            # Find the maximum similarity for points with higher density\n",
        "            mask = densities > densities[i]\n",
        "            eta[i] = similarity_matrix[i, mask].max()\n",
        "        else:\n",
        "            # If the point has the maximum density, find the minimum similarity\n",
        "            eta[i] = similarity_matrix[i].min()\n",
        "\n",
        "    return eta\n",
        "\n",
        "from config import num_prototypes\n",
        "def select_prototypes(similarity_measurement, samples_features, num_prototypes=num_prototypes):\n",
        "    \"\"\"\n",
        "    This function selects the prototypes for a class.\n",
        "    Input: similarity_measurement (torch.Size([randomly_sampled_img_count])),\n",
        "      samples_features (torch.Size([randomly_sampled_img_count, 2048, 1, 1])) and num_prototypes int\n",
        "    Output: class_prototypes tensor (torch.Size([num_prototypes]))\n",
        "    \"\"\"\n",
        "    # Sort the similarity_measurement tensor in descending order and get the indices\n",
        "    sorted_indices = torch.argsort(similarity_measurement, descending=True)\n",
        "\n",
        "    class_prototypes_indices = sorted_indices[:num_prototypes]\n",
        "    # task: select the prototypes from the samples_features based on the indices in class_prototypes_indices\n",
        "    class_prototypes = samples_features[class_prototypes_indices]\n",
        "    return class_prototypes\n",
        "\n",
        "from config import class_names\n",
        "def correct_labels(prototypes, train_features, labels, inputs=None):\n",
        "    \"\"\"\n",
        "    This function corrects the labels by calculating the average similarity scores for each class.\n",
        "    The label of the highest scoring class is selected as the label.\n",
        "    Input: prototypes (list with length of 14 for each class with each instance containing 8 prototypes each with a shape of torch.Size([num_prototypes, 2048, 1, 1])).\n",
        "        train_features (torch.Size([len(train_dataset), 2048, 1, 1]]))\n",
        "    Output: pseudo_labels (Tensor having a the same length as labels)\n",
        "    \"\"\"\n",
        "    pseudo_labels = []\n",
        "\n",
        "    # Iterate over each instance in train_features\n",
        "    for image in train_features:\n",
        "        # Calculate similarity scores for each class\n",
        "        similarity_scores = []\n",
        "        for class_prototypes in prototypes:\n",
        "            # Calculate average similarity score for the class\n",
        "            avg_similarity = torch.mean(torch.cosine_similarity(image, class_prototypes, dim=0))\n",
        "            similarity_scores.append(avg_similarity)\n",
        "\n",
        "        # Select the label of the highest scoring class\n",
        "        highest_score_index = torch.argmax(torch.tensor(similarity_scores))\n",
        "        pseudo_label = labels[highest_score_index]\n",
        "        pseudo_labels.append(pseudo_label)\n",
        "\n",
        "    # Print the percentage of labels changed\n",
        "    changed_labels = sum(pseudo_labels[i] != labels[i] for i in range(len(labels)))\n",
        "    percentage_changed = (changed_labels / len(labels)) * 100\n",
        "    print(f\"Percentage of labels changed: {percentage_changed}%\")\n",
        "\n",
        "    # Visualize the changed labels\n",
        "    for i in range(len(labels)):\n",
        "        if pseudo_labels[i] != labels[i]:\n",
        "            from scripts.supportfunctions import visualize_image\n",
        "            visualize_image(inputs[i], label=f\"{class_names[labels[i]]} → {class_names[pseudo_labels[i]]}\")\n",
        "\n",
        "    return pseudo_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aH1SYtJ35fDF",
        "outputId": "c427e355-aaeb-4f10-b46a-43ebd4025876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1/15, Time: 2846.47 sec\n",
            "Epoch 1\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 82.8125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 79.6875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 79.6875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 75.0%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 99.21875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 99.21875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 82.8125%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 80.46875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 99.21875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 79.6875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 82.8125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 71.875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 78.90625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 78.90625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 82.8125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 88.28125%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 81.25%\n",
            "Percentage of labels changed: 85.9375%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 84.375%\n",
            "Percentage of labels changed: 99.21875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 90.625%\n",
            "Percentage of labels changed: 83.59375%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 99.21875%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 89.0625%\n",
            "Percentage of labels changed: 85.15625%\n",
            "Percentage of labels changed: 96.875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 82.03125%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 96.09375%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 80.46875%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 92.96875%\n",
            "Percentage of labels changed: 91.40625%\n",
            "Percentage of labels changed: 93.75%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 86.71875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 79.6875%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 95.3125%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 98.4375%\n",
            "Percentage of labels changed: 94.53125%\n",
            "Percentage of labels changed: 87.5%\n",
            "Percentage of labels changed: 89.84375%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 97.65625%\n",
            "Percentage of labels changed: 92.1875%\n",
            "Percentage of labels changed: 95.3125%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f18ebe1b266d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mpseudo_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Reset intermediate_output because the model has just seen it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mreset_intermediate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Deep-Self-Learning-From-Noisy-Labels/LoadDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure no leading slash in relative path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load image {img_path} at index {idx}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exclusive_fp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_exclusive_fp_after_loading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from scripts.supportfunctions import evaluate_model, calculate_accuracy\n",
        "# 1. Train the Model\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    model.train() # set model to training mode\n",
        "    epoch_start_time = time.time()  # Start time for the epoch\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move input and label tensors to the device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero out the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # loss is computed differently in first epoch\n",
        "        if epoch == 0:\n",
        "            loss = criterion(outputs, labels)\n",
        "        else:\n",
        "            start_time = time.time()\n",
        "            pseudo_labels = []\n",
        "            for inputs, labels in train_loader:\n",
        "                # reset intermediate_output\n",
        "                reset_intermediate_output()\n",
        "                model(inputs)\n",
        "                # extract features of the samples with the hook \n",
        "                # (automatically saved as intermediate_output)\n",
        "                batch_pseudo_labels = correct_labels(prototypes, \n",
        "                    intermediate_output, labels)\n",
        "                pseudo_labels.extend(batch_pseudo_labels)\n",
        "            # calculate the loss on pseudo and original labels\n",
        "            loss_original = (1-alpha) * criterion(outputs, labels)\n",
        "            loss_pseudo = alpha * criterion(outputs, pseudo_labels)\n",
        "            loss = loss_original + loss_pseudo\n",
        "            end_time = time.time()\n",
        "            print(f\"SMP Loss calculation time: {(end_time - start_time) / 60} minutes\")\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct_predictions += calculate_accuracy(outputs, labels)\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(epoch, model, optimizer, scheduler, best_val_loss, epochs_no_improve, checkpoint_path)\n",
        "\n",
        "\n",
        "    # 2. Label Correction Phase (except in last iteration)\n",
        "    with torch.no_grad():\n",
        "        if epoch != num_epochs-1:\n",
        "            # 2.1 Prototype Selection\n",
        "            # initialize prototypes\n",
        "            prototypes = []\n",
        "            for class_id in range(num_classes):\n",
        "                # Reset the features\n",
        "                reset_intermediate_output()\n",
        "                # sample m=1280 images for the current class\n",
        "                sample_loader = sample_images(class_id)\n",
        "                # feed the randomly sampled images through the model to extract\n",
        "                # the features of the samples with the hook\n",
        "                # (automatically in the intermediate_output variable)\n",
        "                samples_features = []\n",
        "                for inputs in sample_loader:\n",
        "                    inputs = inputs.to(device)\n",
        "                    model(inputs)\n",
        "                    samples_features.append(intermediate_output)\n",
        "                    reset_intermediate_output()\n",
        "                del inputs\n",
        "                # convert to tensor for following operations\n",
        "                samples_features = torch.cat(samples_features)\n",
        "                # calculate similarity matrix of sample features\n",
        "                similarity_matrix = cos_similarity(samples_features)\n",
        "                # calculate the threshold\n",
        "                threshold = calc_similarity_threshold(similarity_matrix)\n",
        "                # calculate density of images\n",
        "                densities = calc_rho_densities(similarity_matrix, threshold)\n",
        "                # calculate similarity measurement\n",
        "                similarity_measurement = calc_eta_similarity_measurement(similarity_matrix, densities)\n",
        "                del similarity_matrix, densities\n",
        "                # select prototypes for each class\n",
        "                class_prototypes = select_prototypes(similarity_measurement, samples_features)\n",
        "                del samples_features\n",
        "                prototypes.append(class_prototypes)\n",
        "            prototypes = torch.cat(prototypes)\n",
        "\n",
        "    epoch_duration = time.time() - epoch_start_time  # End time for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)  # Average loss for the epoch\n",
        "    accuracy = correct_predictions / total_samples  # Accuracy for the epoch\n",
        "\n",
        "    # Log the training loss, accuracy, and duration to TensorBoard\n",
        "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
        "    writer.add_scalar('Time/train', epoch_duration, epoch)\n",
        "\n",
        "    # Validate the model\n",
        "    val_loss, val_accuracy = evaluate_model(val_loader, model, criterion, device)\n",
        "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
        "\n",
        "    # Print the loss, accuracy, and time for every epoch\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "           f'Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
        "        #   f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, '\n",
        "          f'Time: {epoch_duration:.2f} sec')\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}')\n",
        "            early_stop = True\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "hook.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training was manually, stopped with a KeyboardInterrupt because it became evident that the prototype quality is very low. Continuing to train a low performance model for a long time did not justiy the high GPU training costs incurred through Google Colab Pro+. Thus, the SMP approach training was not completed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
