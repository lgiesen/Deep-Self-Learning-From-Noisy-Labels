{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwzqNd1Vg4wi"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wtdbnguQ4aY"
      },
      "source": [
        "Mount Google Drive to access data and other repo files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjKkw5H68gM0",
        "outputId": "1564f28f-2c35-4b49-8298-59350b780b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfgRV3ZQ8tX"
      },
      "source": [
        "Set the seed for reproducability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD7I8qKXQ38W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUjGGMxp_4H_"
      },
      "source": [
        "Delete redundant sample data from Google Colab's session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g46yhAoyLeuB",
        "outputId": "d6a15837-7a33-4151-f7e5-96d5dffc76ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'sample_data' has been deleted.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    if os.path.exists(folder_path):\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder '{folder_path}' has been deleted.\")\n",
        "    else:\n",
        "        print(f\"Folder '{folder_path}' does not exist.\")\n",
        "\n",
        "delete_folder('sample_data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v77OIPU_4IB"
      },
      "source": [
        "Clone the repository to access the other relevant files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFpCBHn9-Xl",
        "outputId": "281d8897-b0e0-4ce4-8441-dbe96947be16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Self-Learning-From-Noisy-Labels'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 128 (delta 70), reused 100 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (128/128), 4.20 MiB | 18.52 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n",
            "/content/Deep-Self-Learning-From-Noisy-Labels\n"
          ]
        }
      ],
      "source": [
        "# clone the repo\n",
        "!git clone https://github.com/lgiesen/Deep-Self-Learning-From-Noisy-Labels.git\n",
        "\n",
        "# go to directory\n",
        "%cd Deep-Self-Learning-From-Noisy-Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyXJNDnV_4IE"
      },
      "source": [
        "Define the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJGD8fw88gM5",
        "outputId": "77291d82-e942-4e01-aefe-a324266044a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': 674373, 'val': 207499}\n",
            "/Users/leori/Code\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leori/Library/Python/3.10/lib/python/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "from config import batch_size, dataset_test_path, dataset_train_path, dataset_val_path\n",
        "from LoadDataset import CustomImageDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    # \"These exact values are used for normalizing data that has been pre-trained\n",
        "    # on the ImageNet dataset. They are based on the statistics of the ImageNet\n",
        "    # dataset, which consists of a large number of natural images.\"\n",
        "    # https://moiseevigor.github.io/software/2022/12/18/one-pager-training-resnet-on-imagenet/\n",
        "\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomImageDataset(file_path=dataset_train_path, transform=transform)\n",
        "val_dataset = CustomImageDataset(file_path=dataset_val_path, transform=transform)\n",
        "test_dataset = CustomImageDataset(file_path=dataset_test_path, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "# pinned memory can significantly speed up the transfer of data between the host and the device (GPU) because the GPU can directly access it\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Prepare dataloaders dictionary\n",
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        "print(dataset_sizes)\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzDPbook_4IF"
      },
      "source": [
        "Extract the image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGoMbLEw20XY",
        "outputId": "dcf8a911-0ffe-4fb0-e970-4137d001da29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/1.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/3.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/4.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/0.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/2.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/5.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/7.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/6.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/9.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "Extracted /content/drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/images/8.tar to ../drive/MyDrive/Colab_Notebooks/Deep_Self_Learning_From_Noisy_Labels/extracted_images/\n",
            "The extracted tar files should result in the folders 0 to 9:\n",
            "0  1  2  3  4  5  6  7\t8  9\n",
            "CPU times: user 3min 51s, sys: 6min 20s, total: 10min 12s\n",
            "Wall time: 5min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import tarfile\n",
        "import os\n",
        "from config import shared_folder_path, dataset_img\n",
        "\n",
        "# Function to extract and process files\n",
        "def extract_and_process(tar_file_path, extract_to):\n",
        "    with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {tar_file_path} to {extract_to}\")\n",
        "\n",
        "parallel_extraction = True\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Function to extract and process files\n",
        "def extract_and_process(tar_file_path, extract_to):\n",
        "    with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {tar_file_path} to {extract_to}\")\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(dataset_img, exist_ok=True)\n",
        "\n",
        "# List of tar files to extract\n",
        "tar_files = [os.path.join(shared_folder_path, f\"{i}.tar\") for i in range(10)]\n",
        "\n",
        "# Function to handle extraction in parallel\n",
        "def extract_tar_files_parallel(tar_files, extract_to):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = [executor.submit(extract_and_process, tar_file, extract_to) for tar_file in tar_files if os.path.exists(tar_file)]\n",
        "        for future in futures:\n",
        "            try:\n",
        "                future.result()  # Wait for the result to ensure any exceptions are raised\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Extract tar files in parallel\n",
        "extract_tar_files_parallel(tar_files, dataset_img)\n",
        "print(\"The extracted tar files should result in the folders 0 to 9:\")\n",
        "!ls \"{dataset_img}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg3-V9AjhANX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5WIYVsj_4IG",
        "outputId": "d88def4a-e0ed-4b4e-de68-7602d3ccfba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from config import lr, momentum, weight_decay, gamma, step_size\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "# Initialize the model\n",
        "#model = models.resnet50(pretrained=True)\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Define a hook function to capture the output before the FC layer\n",
        "def hook_function(module, input, output):\n",
        "    global features\n",
        "    features = output\n",
        "\n",
        "# Register the hook to the layer before the FC layer (AdaptiveAvgPool2d)\n",
        "hook = model.avgpool.register_forward_hook(hook_function)\n",
        "\n",
        "# Parallelize training across multiple GPUs\n",
        "model = torch.nn.DataParallel(model).to(device)\n",
        "\n",
        "# Assuming y_train contains the labels for the training dataset\n",
        "labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "del labels\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "# Initialize the learning rate scheduler: Decay LR by a factor of 0.1 every 5 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "########## Test the hook\n",
        "# Define the input image with the shape [1, 3, 224, 224]\n",
        "input_image = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Pass the input image through the model\n",
        "output = model(input_image)\n",
        "\n",
        "# Unregister the hook\n",
        "hook.remove()\n",
        "\n",
        "# Print the captured features\n",
        "print(features.shape)\n",
        "print(features)\n",
        "\n",
        "# The shape of `features` should be [1, 2048, 1, 1] before it is flattened by the FC layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvDPnKbn4cLu"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgEIt5V4gJJi"
      },
      "outputs": [],
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = outputs.max(1)\n",
        "    correct = predicted.eq(labels).sum().item()\n",
        "    return correct\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(loader, model, criterion, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            correct_predictions += calculate_accuracy(outputs, labels)\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Function to select prototypes based on density and similarity\n",
        "def select_prototypes(features, labels, num_prototypes, similarity_threshold):\n",
        "    similarity_matrix = cosine_similarity(features)\n",
        "    densities = (similarity_matrix > similarity_threshold).sum(axis=1)\n",
        "    prototypes = []\n",
        "    for c in np.unique(labels):\n",
        "        class_indices = np.where(labels == c)[0]\n",
        "        class_densities = densities[class_indices]\n",
        "        sorted_indices = class_indices[np.argsort(-class_densities)]\n",
        "        prototypes.append(sorted_indices[:num_prototypes])\n",
        "    return np.concatenate(prototypes)\n",
        "\n",
        "# Function to correct labels based on prototypes\n",
        "def correct_labels(features, prototypes, prototype_labels):\n",
        "    corrected_labels = []\n",
        "    for feature in features:\n",
        "        similarities = cosine_similarity([feature], prototypes)[0]\n",
        "        class_similarities = np.zeros(np.max(prototype_labels) + 1)\n",
        "        for j, proto_label in enumerate(prototype_labels):\n",
        "            class_similarities[proto_label] += similarities[j]\n",
        "        corrected_labels.append(np.argmax(class_similarities))\n",
        "    return np.array(corrected_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JgD78Wf_4IH",
        "outputId": "d033b206-fce6-44ec-d039-8f1429c04f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Train Loss: 0.7485, Train Accuracy: 0.7680, Val Loss: 0.6389, Val Accuracy: 0.7987, Time: 1951.03 sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from config import num_epochs, dataset_root, similarity_threshold, num_prototypes\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer_path = dataset_root.replace(\"..\", \"/content\") + 'runs/resnet50_experiment'\n",
        "writer = SummaryWriter(writer_path)\n",
        "\n",
        "# 1. Train the Model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    epoch_start_time = time.time()  # Start time for the epoch\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move input and label tensors to the device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero out the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct_predictions += calculate_accuracy(outputs, labels)\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    epoch_duration = time.time() - epoch_start_time  # End time for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)  # Average loss for the epoch\n",
        "    accuracy = correct_predictions / total_samples  # Accuracy for the epoch\n",
        "\n",
        "    # Log the training loss, accuracy, and duration to TensorBoard\n",
        "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
        "    writer.add_scalar('Time/train', epoch_duration, epoch)\n",
        "\n",
        "    # Validate the model\n",
        "    val_loss, val_accuracy = evaluate_model(val_loader, model, criterion, device)\n",
        "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
        "\n",
        "    # Print the loss, accuracy, and time for every epoch\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "          f'Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, '\n",
        "          f'Time: {epoch_duration:.2f} sec')\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # 2. Label Correction Phase (except in last iteration)\n",
        "    if epoch != num_epochs-1:\n",
        "        # 2.1 Prototype Selection\n",
        "        # sample m=1280 images for each class\n",
        "        # extract features with hook\n",
        "        # calculate similarity of features\n",
        "        # calculate density of features\n",
        "        # select 8 prototypes for each class\n",
        "        # get right labels \n",
        "\n",
        "\n",
        "\n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in train_loader:\n",
        "                features = feature_extractor(images)\n",
        "                all_features.append(features)\n",
        "                all_labels.append(labels)\n",
        "        \n",
        "        all_features = torch.cat(all_features).cpu().numpy()\n",
        "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
        "        prototypes_indices = select_prototypes(all_features, all_labels, num_prototypes, similarity_threshold)\n",
        "        prototypes = all_features[prototypes_indices]\n",
        "\n",
        "        # Update dataset labels\n",
        "        train_loader.dataset.labels = corrected_labels\n",
        "        # 2.2 label correction\n",
        "        prototype_labels = all_labels[prototypes_indices]\n",
        "        corrected_labels = correct_labels(all_features, prototypes, prototype_labels)\n",
        "\n",
        "        # TODO ADJUST ALL LABELS train_dataset (CHECK IF TRAIN LOADER IS ALSO ADJUSTED) OR UPDATE NEXT (COUPLE OF?) TRAINING TRAIN LOADERS\n",
        "\n",
        "print(f'Finished Training, Final Train Loss: {avg_loss:.4f}, Final Train Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Test the model\n",
        "test_loss, test_accuracy = evaluate_model(test_loader, model, criterion, device)\n",
        "writer.add_scalar('Loss/test', test_loss, 0)\n",
        "writer.add_scalar('Accuracy/test', test_accuracy, 0)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Close the TensorBoard writer\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6cOck_EUC_W"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(writer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPuy_SP-8gM8"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_path = f'{dataset_root}models/resnet50_clothing1m.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQHq98WETLkN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH-194rSS4HT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isfile(model_path):\n",
        "    print(\"The file exists.\")\n",
        "else:\n",
        "    print(\"The file does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmSUgY5LJkr1"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs-Zu6n48gM8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Define the model (assuming you have already defined and loaded it as before)\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
        "model = models.resnet50(weights=weights)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "# Create a dummy input tensor with the same shape as your input data\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Perform a forward pass using the dummy input\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Visualize the model\n",
        "dot = make_dot(output, params=dict(model.named_parameters()))\n",
        "dot.format = 'png'\n",
        "dot.render(f'{dataset_root}models/resnet50_model')\n",
        "\n",
        "# Display the model graph\n",
        "from IPython.display import Image\n",
        "Image(f'{dataset_root}models/resnet50_model.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFfLgWbug0-b"
      },
      "source": [
        "Evaluate models on validation data with accuracy, precision, recall, F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39KX4RCggv5n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the model (assuming it's saved as a PyTorch model)\n",
        "model = torch.load(model_path)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define a function to evaluate the model\n",
        "def evaluate_model(loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Assuming val_loader and test_loader are defined and contain the data\n",
        "val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(val_loader)\n",
        "test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(test_loader)\n",
        "\n",
        "# Create a DataFrame to store the evaluation results\n",
        "evaluation_results = pd.DataFrame({\n",
        "    'Dataset': ['Validation', 'Test'],\n",
        "    'Accuracy': [val_accuracy, test_accuracy],\n",
        "    'Precision': [val_precision, test_precision],\n",
        "    'Recall': [val_recall, test_recall],\n",
        "    'F1 Score': [val_f1, test_f1]\n",
        "})\n",
        "\n",
        "# Export the evaluation results to a CSV file\n",
        "evaluation_results.to_csv(f'{dataset_root}models/model_evaluation_results.csv', index=False)\n",
        "\n",
        "print(\"Model evaluation completed and results exported.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wORmA_46Jz9U"
      },
      "source": [
        "# To Do\n",
        "\n",
        "- handle class imbalance (oversampling, undersampling, or class weighting to balance the dataset)\n",
        "optional\n",
        "- Hyperparameter tuning to verify statements in the paper"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
